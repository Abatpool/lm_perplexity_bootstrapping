{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corpus bootstrapping with LM perplexity\n",
    "\n",
    "**purpose** here we use domain-specific language model perplexity to extract in-domain sentences from a general \"unlabeled\" corpus (of in-domain and out-of-domain sentences).\n",
    "\n",
    "this is a toy example of Ramaswamy, Printz, Gopalakrishnan: *A Bootstrap Technique for Building Domain-Dependent Language Models*  \n",
    "http://mirlab.org/conference_papers/International_Conference/ICSLP%201998/PDF/SCAN/SL980611.PDF\n",
    "\n",
    "- uses simple bigram LM with add-k smoothing\n",
    "- in-domain data from Jane Austen\n",
    "- 'unlabeled' corpus of Jane Austen, Lewis Carroll and Herman Melville sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import nltk\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in-domain corpus data\n",
    "\n",
    "load the three jane austen texts form NLTK as tokenized sentences and preprocess them\n",
    "\n",
    "(lowercase, remove punctuation etc, add `<s>` and `</s>` tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16498\n"
     ]
    }
   ],
   "source": [
    "# read corpora\n",
    "austen1 = nltk.corpus.gutenberg.sents('austen-emma.txt')\n",
    "austen2 = nltk.corpus.gutenberg.sents('austen-persuasion.txt')\n",
    "austen3 = nltk.corpus.gutenberg.sents('austen-sense.txt')\n",
    "data = austen1 + austen2 + austen3\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4124 12374\n",
      "CPU times: user 5.77 s, sys: 120 ms, total: 5.89 s\n",
      "Wall time: 5.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# shuffle data and withhold random set\n",
    "indices = [i for i in range(len(data))]\n",
    "random.shuffle(indices)\n",
    "data = [data[i] for i in indices]\n",
    "\n",
    "test_idx = int(len(data)*0.25)\n",
    "corpus = data[:test_idx]\n",
    "withheld = data[test_idx:]\n",
    "data = None # clear\n",
    "print(len(corpus), len(withheld))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering in-domain data by length\n",
    "\n",
    "remove sentences of len < 5 (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 3.58 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preprocess data (with function)\n",
    "def preprocess(tokens):\n",
    "    processed = []\n",
    "    for sent in tokens:\n",
    "        if len(sent) > 6:\n",
    "            this_sent = []\n",
    "            for word in sent:\n",
    "                if re.findall(r'[0-9A-Za-z]+', word):\n",
    "                    this_sent.append(word.lower())\n",
    "            this_sent = ['<s>'] + this_sent + ['</s>']\n",
    "            processed.append(this_sent)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed corpus: 3609 withheld: 10886\n"
     ]
    }
   ],
   "source": [
    "corpus = preprocess(corpus)\n",
    "withheld = preprocess(withheld)\n",
    "print(\"seed corpus:\", len(corpus), \"withheld:\", len(withheld))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build bigram language model\n",
    "\n",
    "this is a simple bigram language model with rudimentary Laplace add-k smoothing. we will build it by splitting each sentence into a list of bigram tuples and maintaining a Counter for each tuple.\n",
    "\n",
    "we will constuct this as a function so we can call it repeatedly during the main iterative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def languagemodel(corpus):\n",
    "    \n",
    "    # bigramize and get vocabulary\n",
    "    bigrams = []\n",
    "    vocab = []\n",
    "    for sent in corpus:\n",
    "        # split\n",
    "        for i in range(len(sent)-1):\n",
    "            vocab.append(sent[i])\n",
    "            bigrams.append((sent[i], sent[i+1]))\n",
    "        vocab.append(sent[-1])\n",
    "        \n",
    "    # get vocabulary size, counters\n",
    "    # oovs will be handled by smoothing\n",
    "    vocabsize = len(set(vocab))\n",
    "    vocab_counts = Counter(vocab)\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    \n",
    "    return vocabsize, vocab_counts, bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76 ms, sys: 0 ns, total: 76 ms\n",
      "Wall time: 74.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocabsize, vocab_counts, bigram_counts = languagemodel(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perplexity measurement\n",
    "\n",
    "this is a function of the probability of a given sentence under this language model's assumptions (i.e the product of the probability of each bigram normalized by the total sentence length)\n",
    "\n",
    "we use add-k smoothing to account for out-of-vocab terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity calculation with add-k smoothing\n",
    "# from http://www3.cs.stonybrook.edu/~has/CSE594/Notes/(1)%20Probability%20Theory%20Application%201-28.pdf\n",
    "def perplexity(sent, k=0.1):\n",
    "    # tokenize and bigramize\n",
    "    bigrams = []\n",
    "    for i in range(len(sent)-1):\n",
    "        bigrams.append((sent[i], sent[i+1]))\n",
    "        \n",
    "    # for each bigram, get probability (add-one smoothed)\n",
    "    # p(w_i | w_i-1) = count(w_i-1, w_i) + 1 / count(w_i-1 + N)\n",
    "    probs = []\n",
    "    for bigram in bigrams:\n",
    "        b_c = bigram_counts[bigram] + k\n",
    "        w_c = vocab_counts[bigram[0]] + k*vocabsize\n",
    "        probs.append(b_c/w_c)\n",
    "    \n",
    "    # get inverse\n",
    "    inverse = [1.0/prob for prob in probs]\n",
    "    \n",
    "    # get product\n",
    "    product = 1.0\n",
    "    for inv in inverse:\n",
    "        product *= inv\n",
    "    \n",
    "    # n-th root\n",
    "    perplexity = math.pow(product, (1/len(sent)))\n",
    "    \n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# external corpus\n",
    "\n",
    "this is data from an external source that (hopefully) includes some sentences that we can use for data augmentation.\n",
    "\n",
    "here we (artificially) create a mixed id/ood corpus by mixing our withheld data in with some text from another source. we will use herman melville and lewis carroll because they are authors relatively close in time to jane austen (amongst those included in the NLTK corpus).\n",
    "\n",
    "for evaluation, we will label each sentence according to source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withheld = [('austen', s) for s in withheld]\n",
    "len(withheld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8213, 1360)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melville = nltk.corpus.gutenberg.sents('melville-moby_dick.txt')\n",
    "melville = preprocess(melville)\n",
    "melville = [('melville', s) for s in melville]\n",
    "\n",
    "carroll = nltk.corpus.gutenberg.sents('carroll-alice.txt')\n",
    "carroll = preprocess(carroll)\n",
    "carroll = [('carroll', s) for s in carroll]\n",
    "\n",
    "len(melville), len(carroll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20459"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled = withheld + melville + carroll\n",
    "len(unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test: sort by perplexity score\n",
    "\n",
    "as we can see, in-domain answers are at the top. of course it is not the case that necessarily all *(true)* in-domain sentences are at the top of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 460 ms, sys: 4 ms, total: 464 ms\n",
      "Wall time: 465 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get perplexities\n",
    "perplexities = [perplexity(s[1]) for s in unlabeled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at closest-correlated sentences\n",
    "\n",
    "if we sort by perplexity score (lowest first), hopefully the sentences we get are 'closest' to the known jane austen sentences. as we can see, we don't do too porly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('austen', '<s> i am sure i had not </s>', 17.193319524167045),\n",
       " ('austen', '<s> i have no doubt of it </s>', 18.244950322894468),\n",
       " ('melville', '<s> i am sure that i did not </s>', 19.135558787152608),\n",
       " ('austen', '<s> i am sure you will not like him </s>', 23.203222329802095),\n",
       " ('austen', '<s> i am glad of it </s>', 23.425978832850518),\n",
       " ('austen', '<s> i should be sorry to be more </s>', 24.39050124746715),\n",
       " ('melville', '<s> you must have heard of it </s>', 27.21363298314665),\n",
       " ('austen', '<s> that i am sure you would </s>', 28.750255105743225),\n",
       " ('austen', '<s> she had a great wish to see him </s>', 29.522205060675578),\n",
       " ('austen', '<s> as to that i do not </s>', 31.522506322212063),\n",
       " ('austen', '<s> i am said he </s>', 32.0885518355778),\n",
       " ('austen', '<s> i do not pretend to it </s>', 32.159353910701086),\n",
       " ('austen', '<s> no that he is not </s>', 32.86057514751998),\n",
       " ('austen', '<s> no indeed i do not </s>', 33.00707727014687),\n",
       " ('austen', '<s> i dare say she had </s>', 33.13379749764748),\n",
       " ('austen', '<s> i could not have believed it </s>', 33.313872470097266),\n",
       " ('austen', '<s> i have no patience with him </s>', 33.57717859229776),\n",
       " ('austen', '<s> and this was the end of it </s>', 34.14568948933803),\n",
       " ('austen',\n",
       "  '<s> i was very much pleased with all that he said </s>',\n",
       "  34.22122332068751),\n",
       " ('austen',\n",
       "  '<s> i am sure you must have heard of her before </s>',\n",
       "  34.504262220727135)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by perplexity (lower = better)\n",
    "[(x[0], ' '.join(x[1]), y) for x, y in sorted(zip(unlabeled, perplexities), key=lambda pair: pair[1])][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iterate\n",
    "\n",
    "this is meant to be an iterative algorithm, so we add the top sentences (using threshold) to the original training data, make a new language model, and calculate new perplexity scores over the outside data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 : total added 275 sents\n",
      "iter 20 : total added 525 sents\n",
      "iter 30 : total added 775 sents\n",
      "iter 40 : total added 1025 sents\n",
      "iter 50 : total added 1275 sents\n",
      "iter 60 : total added 1525 sents\n",
      "no added sentences, stopping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iters = 500\n",
    "\n",
    "add_corpus = corpus[:]       # the expanding id-corpus\n",
    "rem_unlabeled = unlabeled[:] # the shrinking unlabeled data\n",
    "additions = []               # track additions to lm corpus\n",
    "threshhold = 100.0           # perplexity threshhold\n",
    "cutoff = 25                  # cutoff for added sents, make large to 'ignore'\n",
    "k = 0.001                    # smoothing term for perplexity add-k smoothing\n",
    "\n",
    "for i in range(iters):\n",
    "    \n",
    "    # EarlyStopping\n",
    "    cnt = 0\n",
    "    \n",
    "    # indices to remove from unlabeled data\n",
    "    remove_idx = []\n",
    "    \n",
    "    # build language model\n",
    "    vocabsize, vocab_counts, bigram_counts = languagemodel(add_corpus)\n",
    "    \n",
    "    # get perplexities\n",
    "    perplexities = [perplexity(s[1], k) for s in rem_unlabeled]\n",
    "    \n",
    "    # indices, sort perplexities\n",
    "    indices = [i for i in range(len(perplexities))]\n",
    "    sorted_perplexities = [(x, y) for x, y in sorted(zip(indices, perplexities), key=lambda pair: pair[1])]\n",
    "    \n",
    "    # take top sents\n",
    "    add = 0\n",
    "    for jdx, tup in enumerate(sorted_perplexities):\n",
    "        idx = tup[0]\n",
    "        perp = tup[1]\n",
    "        if perp < threshhold:\n",
    "            additions.append(rem_unlabeled[idx])\n",
    "            add_corpus.append(rem_unlabeled[idx][1])\n",
    "            remove_idx.append(idx)\n",
    "            cnt += 1\n",
    "            add += 1\n",
    "        if add == cutoff:\n",
    "            break\n",
    "    \n",
    "    # filter out additions\n",
    "    rem_unlabeled = [rem_unlabeled[i] for i in range(len(rem_unlabeled)) if i not in remove_idx]\n",
    "    \n",
    "    # if no added sents, terminate\n",
    "    if cnt == 0:\n",
    "        print(\"no added sentences, stopping...\\n\")\n",
    "        break\n",
    "    \n",
    "    if i > 0 and i % 10 == 0:\n",
    "        print(\"iter\", i, \": total added\", len(additions), \"sents\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation\n",
    "\n",
    "well, looking at the top results from the extracted sentences, we can see that the results subjectively look good in regards to differentiating between jane austen and other texts. but we can also see that perhaps the strongest 'features' are rather trivial: it looks like ('{start}', 'i'), ('i', 'am'), ('i', 'do'), and ('am', 'sure') are probably more highly correlated with austen's works than the others. we could confirm this experimentally by examining counts. a better language model should also help diversify our results. but this does serve to demonstrate the technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('austen', '<s> i am sure i had not </s>', 12.756553442828348),\n",
       " ('austen', '<s> i have no doubt of it </s>', 12.964209650994526),\n",
       " ('melville', '<s> i am sure that i did not </s>', 14.638938101079416),\n",
       " ('austen', '<s> i am glad of it </s>', 14.951632549419598),\n",
       " ('austen', '<s> i am sure you will not like him </s>', 15.053524838875829),\n",
       " ('austen', '<s> i am said he </s>', 19.31944247856956),\n",
       " ('austen', '<s> i should be sorry to be more </s>', 19.65881676454139),\n",
       " ('melville', '<s> you must have heard of it </s>', 19.68569980998823),\n",
       " ('austen', '<s> that i am sure you would </s>', 21.715270354841675),\n",
       " ('austen', '<s> i could not have believed it </s>', 21.958631490355476),\n",
       " ('austen', '<s> i do not think they were </s>', 21.984407431754054),\n",
       " ('austen', '<s> i do not pretend to it </s>', 22.35103112504964),\n",
       " ('austen', '<s> no indeed i do not </s>', 22.447764756276353),\n",
       " ('austen', '<s> she had a great wish to see him </s>', 22.555253968187362),\n",
       " ('austen', '<s> what do you think of him </s>', 22.607380035727182),\n",
       " ('austen', '<s> i dare say she had </s>', 23.451643385482303),\n",
       " ('austen', '<s> i have no patience with him </s>', 23.99442560461422),\n",
       " ('austen', '<s> i assure you i shall not </s>', 24.043973250610843),\n",
       " ('austen',\n",
       "  '<s> i am sure you must have heard of her before </s>',\n",
       "  24.21051195005564),\n",
       " ('austen', '<s> no that he is not </s>', 24.820786971885298)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_perplexities = [perplexity(s[1]) for s in additions]\n",
    "[(x[0], ' '.join(x[1]), y) for x, y in sorted(zip(additions, add_perplexities), key=lambda pair: pair[1])][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sents found: 1646 (% 8.045359010704335 of unlabeled)\n"
     ]
    }
   ],
   "source": [
    "diff = len(add_corpus) - len(corpus)\n",
    "totl = len(unlabeled)\n",
    "print(\"sents found:\", diff, \"(%\", diff*100/totl, \"of unlabeled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of trues in unlabeled: 0.5320885673786597\n"
     ]
    }
   ],
   "source": [
    "punlabeled = len(withheld)/len(withheld + melville + carroll)\n",
    "print(\"percentage of trues in unlabeled:\", punlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of found sents:  0.9270959902794653\n"
     ]
    }
   ],
   "source": [
    "labels = [t[0] for t in additions]\n",
    "corrects = [t[0] for t in additions if t[0]=='austen']\n",
    "print(\"precision of found sents: \", len(corrects)/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall of unlabeled austen sents:  0.14018004776777512\n"
     ]
    }
   ],
   "source": [
    "recall = len(corrects)/len(withheld)\n",
    "print(\"recall of unlabeled austen sents: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
